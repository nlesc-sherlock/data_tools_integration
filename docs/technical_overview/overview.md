# Technological overview of computational designs

In the Sherlock project several teams are working on projects related to / inspired by digital forensics. We are especially looking into analytics of data: (automatically) extracting knowledge from raw data.

## General overview

This is the generic model we use for the analytics done. Not all the work done in Sherlock will fit exactly, but it does cover most usages.

## Deep Learning

by Elena

The deep learning team is creating and using (deep) neural networks for classification of images. This is a two step process. First, a neural network is learned from labeled images.

Next, this network is used to classify images. Learning takes considerable computational effort and thus requires a GPU. Classification of a single image can be done on a normal machine, but classifying large amounts of images does benefit from a GPU.

## Document Collections

by Carlos

## Cluster Analysis

by Ben

## Concept Search / Data Cleaning

by Janneke

## Visualization of Timelines

by Jurriaan

